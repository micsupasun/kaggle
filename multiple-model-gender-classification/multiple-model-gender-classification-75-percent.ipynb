{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# virtualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# scalar, preprocessing\nfrom sklearn import preprocessing\n\n# tuning parameter\nfrom sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,cross_val_score\n\n# model\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom xgboost import XGBClassifier\n\n# metric\nfrom sklearn import model_selection\nfrom sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix,accuracy_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# skip warning\nfrom sklearn import preprocessing\nimport warnings\nwarnings.filterwarnings( action= 'ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-03T08:10:21.162879Z","iopub.execute_input":"2022-09-03T08:10:21.163637Z","iopub.status.idle":"2022-09-03T08:10:22.394590Z","shell.execute_reply.started":"2022-09-03T08:10:21.163438Z","shell.execute_reply":"2022-09-03T08:10:22.393436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"this code aims to use multiple models to find the best model and best parameter to predict","metadata":{}},{"cell_type":"markdown","source":"# IMPORT DATASET","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/gender-classification/Transformed Data Set - Sheet1.csv\")\ndf.info()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:23.705600Z","iopub.execute_input":"2022-09-03T08:10:23.706502Z","iopub.status.idle":"2022-09-03T08:10:23.751948Z","shell.execute_reply.started":"2022-09-03T08:10:23.706464Z","shell.execute_reply":"2022-09-03T08:10:23.750956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESSING DATA","metadata":{}},{"cell_type":"code","source":"# rename for easy to use\ndf = df.rename(columns={'Favorite Color' :'favorite_color', 'Favorite Music Genre':'favorite_music_genre', \n                          'Favorite Beverage':'favorite_beverage', 'Favorite Soft Drink':'favorite_soft_drink'})","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:26.540893Z","iopub.execute_input":"2022-09-03T08:10:26.541254Z","iopub.status.idle":"2022-09-03T08:10:26.547092Z","shell.execute_reply.started":"2022-09-03T08:10:26.541223Z","shell.execute_reply":"2022-09-03T08:10:26.545797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check unique each column\nprint('unique column: favorite_color =',set(df['favorite_color'].tolist()))\nprint('unique column: favorite_music_genre =',set(df['favorite_music_genre'].tolist()))\nprint('unique column: favorite_beverage =',set(df['favorite_beverage'].tolist()))\nprint('unique column: favorite_soft_drink =',set(df['favorite_soft_drink'].tolist()))\nprint('unique column: Gender =',set(df['Gender'].tolist()))","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:26.944384Z","iopub.execute_input":"2022-09-03T08:10:26.945481Z","iopub.status.idle":"2022-09-03T08:10:26.954021Z","shell.execute_reply.started":"2022-09-03T08:10:26.945432Z","shell.execute_reply":"2022-09-03T08:10:26.952579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename for clean data\ndf = df.replace({'favorite_color': {'Warm': 0, 'Cool':1,'Neutral':2},\n                'favorite_music_genre': {'Folk/Traditional': 0, 'Hip hop':1,'Jazz/Blues':2,'Rock':3,'R&B and soul':4,'Pop':5,'Electronic':6},\n                'favorite_beverage': {\"\"\"Doesn't drink\"\"\": 0, \"Whiskey\":1,\"Wine\":2,\"Vodka\":3,\"Other\":4,\"Beer\":5},\n                'favorite_soft_drink': {'Fanta': 0, '7UP/Sprite':1, 'Coca Cola/Pepsi':2,'Other':3},\n                'Gender': {'F': 0, 'M':1}})\ndf.info()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:29.216362Z","iopub.execute_input":"2022-09-03T08:10:29.216741Z","iopub.status.idle":"2022-09-03T08:10:29.252071Z","shell.execute_reply.started":"2022-09-03T08:10:29.216711Z","shell.execute_reply":"2022-09-03T08:10:29.251156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"# check gender dataset\nplt.figure(figsize=(4,6))\ndf[\"Gender\"].hist()  ","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:32.060735Z","iopub.execute_input":"2022-09-03T08:10:32.061714Z","iopub.status.idle":"2022-09-03T08:10:32.301560Z","shell.execute_reply.started":"2022-09-03T08:10:32.061666Z","shell.execute_reply":"2022-09-03T08:10:32.300574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show box plot to find outlier\ndf.plot(kind='box', subplots=True, figsize=(20, 40),layout=(20,4))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:34.731229Z","iopub.execute_input":"2022-09-03T08:10:34.731631Z","iopub.status.idle":"2022-09-03T08:10:37.258578Z","shell.execute_reply.started":"2022-09-03T08:10:34.731596Z","shell.execute_reply":"2022-09-03T08:10:37.257583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"don't have outlier and gender_male and gender_female is equal","metadata":{}},{"cell_type":"markdown","source":"# Train test split","metadata":{}},{"cell_type":"code","source":"# train test split to protect data overfitting\nfeatures = ['favorite_color','favorite_music_genre','favorite_beverage','favorite_soft_drink']\nX = df.loc[:, features].to_numpy()\ny = df.loc[:, 'Gender'].to_numpy()\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:37.620271Z","iopub.execute_input":"2022-09-03T08:10:37.621178Z","iopub.status.idle":"2022-09-03T08:10:37.629530Z","shell.execute_reply.started":"2022-09-03T08:10:37.621141Z","shell.execute_reply":"2022-09-03T08:10:37.628304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train 70% test 30%\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=100)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:39.926721Z","iopub.execute_input":"2022-09-03T08:10:39.927285Z","iopub.status.idle":"2022-09-03T08:10:39.937279Z","shell.execute_reply.started":"2022-09-03T08:10:39.927249Z","shell.execute_reply":"2022-09-03T08:10:39.936031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using standard scalar\nstandard_scaler = preprocessing.StandardScaler()\nX_train_scalar = standard_scaler.fit_transform(X_train)\nX_test_scalar = standard_scaler.fit_transform(X_test)\nprint(X_train_scalar.shape,X_test_scalar.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:42.710599Z","iopub.execute_input":"2022-09-03T08:10:42.711577Z","iopub.status.idle":"2022-09-03T08:10:42.721285Z","shell.execute_reply.started":"2022-09-03T08:10:42.711529Z","shell.execute_reply":"2022-09-03T08:10:42.718848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"# default_parameter with svm\nsvm_model = SVC()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(svm_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nsvm_model.fit(X_train_scalar, y_train)\ny_pred_model =svm_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(svm_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:46.298704Z","iopub.execute_input":"2022-09-03T08:10:46.299138Z","iopub.status.idle":"2022-09-03T08:10:46.549043Z","shell.execute_reply.started":"2022-09-03T08:10:46.299103Z","shell.execute_reply":"2022-09-03T08:10:46.548082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with svm\nsvm_model = SVC()\nsvm_parameter = {\n    'gamma': ['scale','auto'],\n    'verbose':[True,False],\n    'probability':[True,False],\n    'shrinking':[True,False],\n    'break_ties':[True,False],\n    'decision_function_shape': ['ovo','ovr'],\n}\n\nclf = GridSearchCV(svm_model, svm_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:16:58.692747Z","iopub.execute_input":"2022-07-13T19:16:58.693111Z","iopub.status.idle":"2022-07-13T19:16:59.648573Z","shell.execute_reply.started":"2022-07-13T19:16:58.693075Z","shell.execute_reply":"2022-07-13T19:16:59.647665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_parameter with svm\nsvm_model = SVC(break_ties = True, decision_function_shape = 'ovr', gamma = 'scale',probability = True,shrinking=True,verbose=True)\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(svm_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nsvm_model.fit(X_train_scalar, y_train)\ny_pred_model =svm_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(svm_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:10:51.944557Z","iopub.execute_input":"2022-09-03T08:10:51.945549Z","iopub.status.idle":"2022-09-03T08:10:52.194351Z","shell.execute_reply.started":"2022-09-03T08:10:51.945490Z","shell.execute_reply":"2022-09-03T08:10:52.193450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LogisticRegression","metadata":{}},{"cell_type":"code","source":"# default parameter with LogisticRegression\nlogistic_regrssion_model = LogisticRegression()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(logistic_regrssion_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nlogistic_regrssion_model.fit(X_train_scalar, y_train)\ny_pred_model =svm_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(svm_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:09.262896Z","iopub.execute_input":"2022-09-03T08:11:09.263466Z","iopub.status.idle":"2022-09-03T08:11:09.597962Z","shell.execute_reply.started":"2022-09-03T08:11:09.263425Z","shell.execute_reply":"2022-09-03T08:11:09.596854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with LogisticRegression\nlogistic_regression_model = LogisticRegression()\nlogistic_regression_parameter = {    \n    'penalty': ['l1','l2','elasticnet','none'],\n    'dual': [True,False],\n    'fit_intercept': [True,False],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n    'max_iter': [100,200,400,800],\n    'multi_class': ['auto','ovr','multinomial'],\n}\n\nclf = GridSearchCV(logistic_regression_model, logistic_regression_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:17:00.111752Z","iopub.execute_input":"2022-07-13T19:17:00.112211Z","iopub.status.idle":"2022-07-13T19:17:05.235070Z","shell.execute_reply.started":"2022-07-13T19:17:00.112174Z","shell.execute_reply":"2022-07-13T19:17:05.233354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning parameter with LogisticRegression\nlogistic_regrssion_model = LogisticRegression(dual= False, fit_intercept= True, max_iter= 100, multi_class= 'auto', penalty= 'l1', solver= 'saga')\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(logistic_regrssion_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nlogistic_regrssion_model.fit(X_train_scalar, y_train)\ny_pred_model =svm_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(svm_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:13.683442Z","iopub.execute_input":"2022-09-03T08:11:13.683841Z","iopub.status.idle":"2022-09-03T08:11:13.938545Z","shell.execute_reply.started":"2022-09-03T08:11:13.683810Z","shell.execute_reply":"2022-09-03T08:11:13.937520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"# default regression with DecisionTreeClassifier\ndecision_tree_classifier_model = DecisionTreeClassifier()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(decision_tree_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\ndecision_tree_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =decision_tree_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(decision_tree_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:18.256086Z","iopub.execute_input":"2022-09-03T08:11:18.256452Z","iopub.status.idle":"2022-09-03T08:11:18.496434Z","shell.execute_reply.started":"2022-09-03T08:11:18.256421Z","shell.execute_reply":"2022-09-03T08:11:18.495471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with DecisionTreeClassifier\ndecision_tree_classifier_model = DecisionTreeClassifier()\ndecision_tree_classifier_parameter = {\n    'criterion': [\"gini\", \"entropy\"],\n    'splitter': [\"best\",\"random\"],\n    'max_depth': [3,5,None],\n    'min_samples_split': [2,4,8],\n    'min_samples_leaf': [1,2,4],\n    'max_features':['auto','sqrt','log2']\n}\n\nclf = GridSearchCV(decision_tree_classifier_model, decision_tree_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:17:05.661668Z","iopub.execute_input":"2022-07-13T19:17:05.662122Z","iopub.status.idle":"2022-07-13T19:17:07.463062Z","shell.execute_reply.started":"2022-07-13T19:17:05.662084Z","shell.execute_reply":"2022-07-13T19:17:07.462045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_parameter with DecisionTreeClassifier\ndecision_tree_classifier_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = None, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 2, splitter = 'random')\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(decision_tree_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\ndecision_tree_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =decision_tree_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(decision_tree_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:22.015610Z","iopub.execute_input":"2022-09-03T08:11:22.016011Z","iopub.status.idle":"2022-09-03T08:11:22.257890Z","shell.execute_reply.started":"2022-09-03T08:11:22.015982Z","shell.execute_reply":"2022-09-03T08:11:22.257051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNeighborsClassifier","metadata":{}},{"cell_type":"code","source":"# default regression with KNeighborsClassifier\nKNeighbors_classifier_model = KNeighborsClassifier()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(KNeighbors_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nKNeighbors_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =KNeighbors_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(KNeighbors_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:26.919578Z","iopub.execute_input":"2022-09-03T08:11:26.920298Z","iopub.status.idle":"2022-09-03T08:11:27.174844Z","shell.execute_reply.started":"2022-09-03T08:11:26.920259Z","shell.execute_reply":"2022-09-03T08:11:27.173781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with KNeighborsClassifier\nKNeighbors_classifier_model = KNeighborsClassifier()\nKNeighbors_classifier_parameter = {\n    'n_neighbors': [5,7,9],\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n    'p': [1,2],\n}\n\nclf = GridSearchCV(KNeighbors_classifier_model, KNeighbors_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:17:07.909040Z","iopub.execute_input":"2022-07-13T19:17:07.909483Z","iopub.status.idle":"2022-07-13T19:17:08.520773Z","shell.execute_reply.started":"2022-07-13T19:17:07.909444Z","shell.execute_reply":"2022-07-13T19:17:08.519852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_parameter with KNeighborsClassifier\nKNeighbors_classifier_model = KNeighborsClassifier(algorithm = 'auto', n_neighbors = 7, p = 1, weights = 'distance')\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(KNeighbors_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nKNeighbors_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =KNeighbors_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(KNeighbors_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:31.965729Z","iopub.execute_input":"2022-09-03T08:11:31.966491Z","iopub.status.idle":"2022-09-03T08:11:32.232578Z","shell.execute_reply.started":"2022-09-03T08:11:31.966453Z","shell.execute_reply":"2022-09-03T08:11:32.231504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GaussianNB","metadata":{}},{"cell_type":"code","source":"# default regression with GaussianNB\ngaussian_nb_classifier_model = GaussianNB()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(gaussian_nb_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\ngaussian_nb_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =gaussian_nb_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(gaussian_nb_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:36.810843Z","iopub.execute_input":"2022-09-03T08:11:36.811250Z","iopub.status.idle":"2022-09-03T08:11:37.045731Z","shell.execute_reply.started":"2022-09-03T08:11:36.811216Z","shell.execute_reply":"2022-09-03T08:11:37.044812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with GaussianNB\ngaussian_nb_classifier_model = GaussianNB()\ngaussian_nb_classifier_parameter = {\n    'priors':[0.1,0.5, 0.9,None]\n}\n\nclf = GridSearchCV(gaussian_nb_classifier_model, gaussian_nb_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:17:08.952360Z","iopub.execute_input":"2022-07-13T19:17:08.952802Z","iopub.status.idle":"2022-07-13T19:17:08.983485Z","shell.execute_reply.started":"2022-07-13T19:17:08.952757Z","shell.execute_reply":"2022-07-13T19:17:08.982518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_parameter with GaussianNB\ngaussian_nb_classifier_model = GaussianNB(priors = None)\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(gaussian_nb_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\ngaussian_nb_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =gaussian_nb_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(gaussian_nb_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:43.909834Z","iopub.execute_input":"2022-09-03T08:11:43.910230Z","iopub.status.idle":"2022-09-03T08:11:44.146410Z","shell.execute_reply.started":"2022-09-03T08:11:43.910200Z","shell.execute_reply":"2022-09-03T08:11:44.145448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SGDClassifier","metadata":{}},{"cell_type":"code","source":"# default regression with SGDClassifier\nsgd_classifier_model = SGDClassifier()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(sgd_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nsgd_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =sgd_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(sgd_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:11:47.614437Z","iopub.execute_input":"2022-09-03T08:11:47.615609Z","iopub.status.idle":"2022-09-03T08:11:48.138373Z","shell.execute_reply.started":"2022-09-03T08:11:47.615537Z","shell.execute_reply":"2022-09-03T08:11:48.137460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with SGDClassifier\nsgd_classifier_model = SGDClassifier()\nsgd_classifier_parameter = {\n    'penalty': ['l2', 'l1', 'elasticnet'],\n    'l1_ratio': [0.15,0.50,0.85],\n    'fit_intercept': [True,False],\n    'max_iter': [1000,2000,4000],\n    'shuffle': [True,False],\n    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n}\n\nclf = GridSearchCV(sgd_classifier_model, sgd_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:17:09.414389Z","iopub.execute_input":"2022-07-13T19:17:09.414744Z","iopub.status.idle":"2022-07-13T19:17:11.568770Z","shell.execute_reply.started":"2022-07-13T19:17:09.414709Z","shell.execute_reply":"2022-07-13T19:17:11.567832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_parameter with SGDClassifier\nsgd_classifier_model = SGDClassifier(fit_intercept = False, l1_ratio = 0.85, learning_rate = 'optimal', max_iter = 1000, penalty = 'l2', shuffle = True)\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(sgd_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nsgd_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =sgd_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(sgd_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:01.252005Z","iopub.execute_input":"2022-09-03T08:12:01.252366Z","iopub.status.idle":"2022-09-03T08:12:01.484657Z","shell.execute_reply.started":"2022-09-03T08:12:01.252337Z","shell.execute_reply":"2022-09-03T08:12:01.483582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"# default regression with RandomForestClassifier\nrandom_forest_classifier_model = RandomForestClassifier()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(random_forest_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nrandom_forest_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =random_forest_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(random_forest_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:05.123475Z","iopub.execute_input":"2022-09-03T08:12:05.124260Z","iopub.status.idle":"2022-09-03T08:12:06.792477Z","shell.execute_reply.started":"2022-09-03T08:12:05.124224Z","shell.execute_reply":"2022-09-03T08:12:06.791529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with RandomForestClassifier\nrandom_forest_classifier_model = RandomForestClassifier()\nrandom_forest_classifier_parameter = {\n    'n_estimators': [100,400,700,1000],\n    'max_features': [\"auto\", \"sqrt\"],\n    'max_depth' : [3,5,None],\n    'min_samples_split' : [2, 5, 10],\n    'min_samples_leaf' : [1, 2, 4],\n    'bootstrap': [True, False],\n}\n\nclf = GridSearchCV(random_forest_classifier_model, random_forest_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:17:13.631902Z","iopub.execute_input":"2022-07-13T19:17:13.632250Z","iopub.status.idle":"2022-07-13T19:43:11.335718Z","shell.execute_reply.started":"2022-07-13T19:17:13.632213Z","shell.execute_reply":"2022-07-13T19:43:11.334648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_parameter with RandomForestClassifier\nrandom_forest_classifier_model = RandomForestClassifier(n_estimators = 700, max_features = \"auto\", max_depth = None, min_samples_leaf =1,bootstrap =True,min_samples_split=2)\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(random_forest_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nrandom_forest_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =random_forest_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(random_forest_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:11.025600Z","iopub.execute_input":"2022-09-03T08:12:11.026430Z","iopub.status.idle":"2022-09-03T08:12:21.753266Z","shell.execute_reply.started":"2022-09-03T08:12:11.026392Z","shell.execute_reply":"2022-09-03T08:12:21.752357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBClassifier","metadata":{}},{"cell_type":"code","source":"# default regression with XGBClassifier\nxgb_classifier_model = XGBClassifier()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(xgb_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nxgb_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =xgb_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(xgb_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:21.756186Z","iopub.execute_input":"2022-09-03T08:12:21.756932Z","iopub.status.idle":"2022-09-03T08:12:25.125622Z","shell.execute_reply.started":"2022-09-03T08:12:21.756890Z","shell.execute_reply":"2022-09-03T08:12:25.124527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with XGBClassifier\nxgb_classifier_model = XGBClassifier()\nxgb_classifier_parameter = {\n    'max_depth': [ 3, 4, 5, 6, 8, 10, 12, 15 ],\n#     'learning_rate': [ 0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ],\n#     'n_estimators': [ 50, 75, 100, 125, 150 ],\n#     'min_child_weight': [ 1, 3, 5, 7 ],\n#     'gamma': [ 0.0, 0.1, 0.2, 0.3, 0.4 ],\n#     'colsample_bytree': [ 0.3, 0.4, 0.5, 0.7 ] \n}\n\nclf = GridSearchCV(xgb_classifier_model, xgb_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:43:20.372105Z","iopub.execute_input":"2022-07-13T19:43:20.372553Z","iopub.status.idle":"2022-07-13T19:43:21.338145Z","shell.execute_reply.started":"2022-07-13T19:43:20.372512Z","shell.execute_reply":"2022-07-13T19:43:21.337349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning parameter with XGBClassifier\nxgb_classifier_model = XGBClassifier(max_depth =3)\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(xgb_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nxgb_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =xgb_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(xgb_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:25.128075Z","iopub.execute_input":"2022-09-03T08:12:25.129138Z","iopub.status.idle":"2022-09-03T08:12:26.893448Z","shell.execute_reply.started":"2022-09-03T08:12:25.129096Z","shell.execute_reply":"2022-09-03T08:12:26.892550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multi layer perceptron","metadata":{}},{"cell_type":"code","source":"# default regression with MLPClassifier\nmlp_classifier_model = MLPClassifier()\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(mlp_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nmlp_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =mlp_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(mlp_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:27.717962Z","iopub.execute_input":"2022-09-03T08:12:27.718322Z","iopub.status.idle":"2022-09-03T08:12:29.150685Z","shell.execute_reply.started":"2022-09-03T08:12:27.718293Z","shell.execute_reply":"2022-09-03T08:12:29.149741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find_best_parameter with MLPClassifier\nmlp_classifier_model = MLPClassifier()\nmlp_classifier_parameter = {\n    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n    'solver': ['lbfgs', 'sgd', 'adam'],\n#     'power_t': [0.1,0.5,0.8],\n    'max_iter': [200,800,1600],\n#     'shuffle': [True,False],\n#     'verbose': [True,False],\n#     'warm_start': [True,False],\n#     'nesterovs_momentum': [True,False],\n#     'early_stopping': [True,False],\n#     'validation_fraction': [0.1,0.5,0.8]\n}\n\nclf = GridSearchCV(mlp_classifier_model, mlp_classifier_parameter)\nclf.fit(X_train_scalar, y_train)\nprint(\"\\nbest_score = \",clf.best_score_)\nprint(\"best_params = \",clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:43:23.428078Z","iopub.execute_input":"2022-07-13T19:43:23.428747Z","iopub.status.idle":"2022-07-13T19:43:47.409389Z","shell.execute_reply.started":"2022-07-13T19:43:23.428707Z","shell.execute_reply":"2022-07-13T19:43:47.408389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning parameter with MLPClassifier\nmlp_classifier_model = MLPClassifier(activation = 'relu',solver = 'adam',max_iter =200)\nkfold = model_selection.KFold(n_splits=10)\ncv = model_selection.cross_val_score(mlp_classifier_model, X_train_scalar, y_train, cv=kfold)\ncv_mean = cv.mean()\ncv_std = cv.std()\nprint('mean =',cv_mean)\nprint('std =',cv_std)\nmlp_classifier_model.fit(X_train_scalar, y_train)\ny_pred_model =mlp_classifier_model.predict(X_test_scalar)\nprint('accuracy_score = ',accuracy_score(y_test, y_pred_model))\nprint(classification_report(y_test, y_pred_model))\nplot_confusion_matrix(mlp_classifier_model, X_test_scalar, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:32.084185Z","iopub.execute_input":"2022-09-03T08:12:32.084570Z","iopub.status.idle":"2022-09-03T08:12:33.661348Z","shell.execute_reply.started":"2022-09-03T08:12:32.084533Z","shell.execute_reply":"2022-09-03T08:12:33.660374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_default_parameter = pd.DataFrame({\n    'model':['svm','LogisticRegression','DecisionTreeClassifier','KNeighborsClassifier','GaussianNB','SGDClassifier','RandomForestClassifier','XGBClassifier','MLPClassifier'],\n    'accuracy': [0.7,0.7,0.65,0.45,0.4,0.4,0.6,0.65,0.75]\n})\ndf_default_parameter","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:39.284711Z","iopub.execute_input":"2022-09-03T08:12:39.285327Z","iopub.status.idle":"2022-09-03T08:12:39.299642Z","shell.execute_reply.started":"2022-09-03T08:12:39.285284Z","shell.execute_reply":"2022-09-03T08:12:39.298645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compare default parameter\nplt.figure(figsize=(40,20))\nsns.set_theme(style=\"whitegrid\")\nax = sns.barplot(x=\"model\", y=\"accuracy\", data=df_default_parameter)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:43.063363Z","iopub.execute_input":"2022-09-03T08:12:43.064146Z","iopub.status.idle":"2022-09-03T08:12:43.492504Z","shell.execute_reply.started":"2022-09-03T08:12:43.064108Z","shell.execute_reply":"2022-09-03T08:12:43.491555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tuning_parameter = pd.DataFrame({\n    'model':['svm','LogisticRegression','DecisionTreeClassifier','KNeighborsClassifier','GaussianNB','SGDClassifier','RandomForestClassifier','XGBClassifier','MLPClassifier'],\n    'accuracy': [0.7,0.7,0.75,0.6,0.4,0.6,0.7,0.65,0.75]\n})\ndf_tuning_parameter","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:46.477225Z","iopub.execute_input":"2022-09-03T08:12:46.477678Z","iopub.status.idle":"2022-09-03T08:12:46.491872Z","shell.execute_reply.started":"2022-09-03T08:12:46.477643Z","shell.execute_reply":"2022-09-03T08:12:46.490396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compare default parameter\nplt.figure(figsize=(40,20))\nsns.set_theme(style=\"whitegrid\")\nax = sns.barplot(x=\"model\", y=\"accuracy\", data=df_tuning_parameter)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T08:12:49.219339Z","iopub.execute_input":"2022-09-03T08:12:49.220329Z","iopub.status.idle":"2022-09-03T08:12:49.620186Z","shell.execute_reply.started":"2022-09-03T08:12:49.220284Z","shell.execute_reply":"2022-09-03T08:12:49.619201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"# limitation\nThe reason why the accuracy does not exceed 80 percent and the predicted volatility is due to the very small number of datasets.\n# advantage\n1. data is relatively clean and columns are relatively few, easy to get started with.\n2. Relatively less data means less training time.","metadata":{}},{"cell_type":"markdown","source":"Finally!!!!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}